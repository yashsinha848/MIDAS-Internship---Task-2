{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midas-1-1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86u97NOVvi99",
        "outputId": "75e9e036-4629-4b4c-d2c1-f0edf86ce2ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEmX5cDL8IH1"
      },
      "source": [
        "The codeblock is loading all the needed libraries needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOouDTJa3QjI"
      },
      "source": [
        "#Loading all the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras import regularizers\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from PIL import Image\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
        "from IPython.display import display\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWlqCh-U5DAK"
      },
      "source": [
        "What the code block is doing-\n",
        "It is loading the training images from google drive then few more images are generated from ImageDataGenerator from the training images . Then those images are preprocessed by converting them to grayscale image and making their size small.\n",
        "\n",
        "ImageDataGenerator has been used because it creates new images from the existing images for the model to train on. It creates new images by rotating the images by rotation_range specified, by randomly horizontally flipping the images , by zooming the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuD0Rex1aBLp",
        "outputId": "714370e4-5ef2-4fab-e688-8e04b6529ed5"
      },
      "source": [
        "num_classes = 62\n",
        "# Size of the images\n",
        "img_h,img_w = 48,48\n",
        "batch_size = 20\n",
        "train_data_dir = r'/content/drive/My Drive/train'   #Location of training data\n",
        "train_datagen = ImageDataGenerator(           #Used to generate more images\n",
        "\t\t\t\t\trescale=1./255,\n",
        "\t\t\t\t\trotation_range=30,\n",
        "\t\t\t\t\tshear_range=0.3,\n",
        "\t\t\t\t\tzoom_range=0.3,\n",
        "\t\t\t\t\twidth_shift_range=0.4,\n",
        "\t\t\t\t\theight_shift_range=0.4,\n",
        "\t\t\t\t\thorizontal_flip=True)\n",
        "train_generator = train_datagen.flow_from_directory(     #Preprocessing the training images\n",
        "\t\t\t\t\ttrain_data_dir,\n",
        "\t\t\t\t\tcolor_mode='grayscale',\n",
        "\t\t\t\t\ttarget_size=(img_h,img_w),\n",
        "\t\t\t\t\tbatch_size=batch_size,\n",
        "\t\t\t\t\tclass_mode='categorical',\n",
        "\t\t\t\t\tshuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2480 images belonging to 62 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtjOoO2m8wTS"
      },
      "source": [
        "Convolutional Neural network model is defined using relu and softmax activation layers. The model is compiled using Adam optimizer and using categorical_crossentropy as loss function. Then the model is fitted on the training data for 200 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "go2B5FYLTeVq",
        "outputId": "fd3baa34-9f3e-4b5c-f201-a16e2d83ea6c"
      },
      "source": [
        "model = Sequential()                               #Sequential model is defined\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256,(3,3),padding='same',kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(64,kernel_initializer='he_normal'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(num_classes,kernel_initializer='he_normal'))           #Last layer has 62 output layers\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath = '/content/drive/My Drive/train/checkp.hdf5', monitor='accuracy', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "model.compile(loss='categorical_crossentropy',       #Model is compiled\n",
        "              optimizer = Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "nb_train_samples = 2480\n",
        "epochs=200\n",
        "history=model.fit(                                   #Model is fitted on the training data\n",
        "                train_generator,\n",
        "                steps_per_epoch=100,\n",
        "                epochs=epochs,\n",
        "                callbacks = [checkpointer])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/200\n",
            "100/100 [==============================] - 313s 3s/step - loss: 4.8541 - accuracy: 0.0144\n",
            "Epoch 2/200\n",
            "100/100 [==============================] - 90s 894ms/step - loss: 4.3670 - accuracy: 0.0348\n",
            "Epoch 3/200\n",
            "100/100 [==============================] - 40s 403ms/step - loss: 4.3164 - accuracy: 0.0255\n",
            "Epoch 4/200\n",
            "100/100 [==============================] - 30s 296ms/step - loss: 4.2139 - accuracy: 0.0181\n",
            "Epoch 5/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 4.1633 - accuracy: 0.0280\n",
            "Epoch 6/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 4.1235 - accuracy: 0.0331\n",
            "Epoch 7/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 4.0347 - accuracy: 0.0398\n",
            "Epoch 8/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 3.9620 - accuracy: 0.0437\n",
            "Epoch 9/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 3.9148 - accuracy: 0.0441\n",
            "Epoch 10/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 3.9597 - accuracy: 0.0359\n",
            "Epoch 11/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 3.8391 - accuracy: 0.0562\n",
            "Epoch 12/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 3.8248 - accuracy: 0.0426\n",
            "Epoch 13/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 3.7495 - accuracy: 0.0593\n",
            "Epoch 14/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 3.7481 - accuracy: 0.0642\n",
            "Epoch 15/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 3.6906 - accuracy: 0.0552\n",
            "Epoch 16/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 3.6525 - accuracy: 0.0613\n",
            "Epoch 17/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 3.6217 - accuracy: 0.0647\n",
            "Epoch 18/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 3.5509 - accuracy: 0.0651\n",
            "Epoch 19/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 3.5297 - accuracy: 0.0810\n",
            "Epoch 20/200\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 3.4848 - accuracy: 0.0906\n",
            "Epoch 21/200\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 3.3605 - accuracy: 0.0962\n",
            "Epoch 22/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 3.3403 - accuracy: 0.1060\n",
            "Epoch 23/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 3.2619 - accuracy: 0.1094\n",
            "Epoch 24/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 3.2609 - accuracy: 0.1250\n",
            "Epoch 25/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 3.1695 - accuracy: 0.1354\n",
            "Epoch 26/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 3.1059 - accuracy: 0.1645\n",
            "Epoch 27/200\n",
            "100/100 [==============================] - 30s 296ms/step - loss: 2.9529 - accuracy: 0.1653\n",
            "Epoch 28/200\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 2.8784 - accuracy: 0.2039\n",
            "Epoch 29/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 2.7817 - accuracy: 0.2026\n",
            "Epoch 30/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 2.6719 - accuracy: 0.2420\n",
            "Epoch 31/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 2.6072 - accuracy: 0.2474\n",
            "Epoch 32/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 2.4968 - accuracy: 0.2749\n",
            "Epoch 33/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 2.4367 - accuracy: 0.2974\n",
            "Epoch 34/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 2.4367 - accuracy: 0.2787\n",
            "Epoch 35/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 2.3273 - accuracy: 0.3348\n",
            "Epoch 36/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 2.3319 - accuracy: 0.3075\n",
            "Epoch 37/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 2.2387 - accuracy: 0.3263\n",
            "Epoch 38/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 2.1900 - accuracy: 0.3315\n",
            "Epoch 39/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 2.1851 - accuracy: 0.3534\n",
            "Epoch 40/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 2.1018 - accuracy: 0.3928\n",
            "Epoch 41/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 1.9900 - accuracy: 0.3995\n",
            "Epoch 42/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.9874 - accuracy: 0.4275\n",
            "Epoch 43/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.9890 - accuracy: 0.3969\n",
            "Epoch 44/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 2.0400 - accuracy: 0.3959\n",
            "Epoch 45/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 1.9166 - accuracy: 0.4159\n",
            "Epoch 46/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 1.9399 - accuracy: 0.4361\n",
            "Epoch 47/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 1.8649 - accuracy: 0.4321\n",
            "Epoch 48/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 1.8026 - accuracy: 0.4535\n",
            "Epoch 49/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 1.7925 - accuracy: 0.4774\n",
            "Epoch 50/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.8265 - accuracy: 0.4538\n",
            "Epoch 51/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.7471 - accuracy: 0.4683\n",
            "Epoch 52/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.8211 - accuracy: 0.4543\n",
            "Epoch 53/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.6843 - accuracy: 0.4927\n",
            "Epoch 54/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.7992 - accuracy: 0.4645\n",
            "Epoch 55/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.6399 - accuracy: 0.4717\n",
            "Epoch 56/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 1.8204 - accuracy: 0.4496\n",
            "Epoch 57/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 1.5617 - accuracy: 0.5329\n",
            "Epoch 58/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 1.6321 - accuracy: 0.5041\n",
            "Epoch 59/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 1.6582 - accuracy: 0.4907\n",
            "Epoch 60/200\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 1.6140 - accuracy: 0.5111\n",
            "Epoch 61/200\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 1.6566 - accuracy: 0.4883\n",
            "Epoch 62/200\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 1.6451 - accuracy: 0.5118\n",
            "Epoch 63/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.5701 - accuracy: 0.5096\n",
            "Epoch 64/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.6253 - accuracy: 0.4966\n",
            "Epoch 65/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.5391 - accuracy: 0.5211\n",
            "Epoch 66/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.5914 - accuracy: 0.5112\n",
            "Epoch 67/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.5484 - accuracy: 0.5333\n",
            "Epoch 68/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.5412 - accuracy: 0.5215\n",
            "Epoch 69/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.4357 - accuracy: 0.5574\n",
            "Epoch 70/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 1.4784 - accuracy: 0.5592\n",
            "Epoch 71/200\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 1.4978 - accuracy: 0.5327\n",
            "Epoch 72/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.4676 - accuracy: 0.5560\n",
            "Epoch 73/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.3951 - accuracy: 0.5711\n",
            "Epoch 74/200\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 1.4805 - accuracy: 0.5692\n",
            "Epoch 75/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.4220 - accuracy: 0.5728\n",
            "Epoch 76/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.4969 - accuracy: 0.5579\n",
            "Epoch 77/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.4739 - accuracy: 0.5548\n",
            "Epoch 78/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.4268 - accuracy: 0.5603\n",
            "Epoch 79/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.3545 - accuracy: 0.5735\n",
            "Epoch 80/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.2936 - accuracy: 0.6117\n",
            "Epoch 81/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.3119 - accuracy: 0.6031\n",
            "Epoch 82/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.3408 - accuracy: 0.5760\n",
            "Epoch 83/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.3959 - accuracy: 0.5582\n",
            "Epoch 84/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.3504 - accuracy: 0.5888\n",
            "Epoch 85/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 1.2484 - accuracy: 0.6181\n",
            "Epoch 86/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.4176 - accuracy: 0.5861\n",
            "Epoch 87/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.3006 - accuracy: 0.5803\n",
            "Epoch 88/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.3219 - accuracy: 0.5677\n",
            "Epoch 89/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.3030 - accuracy: 0.5918\n",
            "Epoch 90/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1954 - accuracy: 0.6193\n",
            "Epoch 91/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.3210 - accuracy: 0.5896\n",
            "Epoch 92/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.3215 - accuracy: 0.5881\n",
            "Epoch 93/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.1755 - accuracy: 0.6268\n",
            "Epoch 94/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 1.2993 - accuracy: 0.6044\n",
            "Epoch 95/200\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 1.1953 - accuracy: 0.6376\n",
            "Epoch 96/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.2223 - accuracy: 0.5977\n",
            "Epoch 97/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.2502 - accuracy: 0.6184\n",
            "Epoch 98/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.2024 - accuracy: 0.6297\n",
            "Epoch 99/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.1849 - accuracy: 0.6286\n",
            "Epoch 100/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.1477 - accuracy: 0.6674\n",
            "Epoch 101/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.1793 - accuracy: 0.6353\n",
            "Epoch 102/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1543 - accuracy: 0.6588\n",
            "Epoch 103/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.1612 - accuracy: 0.6377\n",
            "Epoch 104/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.1748 - accuracy: 0.6315\n",
            "Epoch 105/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.1819 - accuracy: 0.6285\n",
            "Epoch 106/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.1996 - accuracy: 0.6341\n",
            "Epoch 107/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1627 - accuracy: 0.6487\n",
            "Epoch 108/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.1051 - accuracy: 0.6762\n",
            "Epoch 109/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.0914 - accuracy: 0.6709\n",
            "Epoch 110/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1603 - accuracy: 0.6287\n",
            "Epoch 111/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1714 - accuracy: 0.6460\n",
            "Epoch 112/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1122 - accuracy: 0.6587\n",
            "Epoch 113/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.0371 - accuracy: 0.6731\n",
            "Epoch 114/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.1412 - accuracy: 0.6490\n",
            "Epoch 115/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.1300 - accuracy: 0.6755\n",
            "Epoch 116/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.0323 - accuracy: 0.6759\n",
            "Epoch 117/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 1.0800 - accuracy: 0.6581\n",
            "Epoch 118/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.1024 - accuracy: 0.6544\n",
            "Epoch 119/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 1.0635 - accuracy: 0.6369\n",
            "Epoch 120/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.1185 - accuracy: 0.6421\n",
            "Epoch 121/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.1306 - accuracy: 0.6337\n",
            "Epoch 122/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.0594 - accuracy: 0.6797\n",
            "Epoch 123/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.0850 - accuracy: 0.6617\n",
            "Epoch 124/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 1.1201 - accuracy: 0.6639\n",
            "Epoch 125/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.0040 - accuracy: 0.6884\n",
            "Epoch 126/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.0826 - accuracy: 0.6548\n",
            "Epoch 127/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 1.0463 - accuracy: 0.6762\n",
            "Epoch 128/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.0246 - accuracy: 0.6745\n",
            "Epoch 129/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.0330 - accuracy: 0.6745\n",
            "Epoch 130/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.0338 - accuracy: 0.6713\n",
            "Epoch 131/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.0242 - accuracy: 0.6760\n",
            "Epoch 132/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.0659 - accuracy: 0.6625\n",
            "Epoch 133/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.1119 - accuracy: 0.6555\n",
            "Epoch 134/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 1.0552 - accuracy: 0.6807\n",
            "Epoch 135/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9664 - accuracy: 0.6958\n",
            "Epoch 136/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9632 - accuracy: 0.6986\n",
            "Epoch 137/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.0418 - accuracy: 0.6675\n",
            "Epoch 138/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 1.0573 - accuracy: 0.6777\n",
            "Epoch 139/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.0507 - accuracy: 0.6724\n",
            "Epoch 140/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 1.0357 - accuracy: 0.6683\n",
            "Epoch 141/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.9110 - accuracy: 0.7225\n",
            "Epoch 142/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 1.0445 - accuracy: 0.6766\n",
            "Epoch 143/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.9103 - accuracy: 0.7295\n",
            "Epoch 144/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 1.0375 - accuracy: 0.6732\n",
            "Epoch 145/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.8978 - accuracy: 0.7317\n",
            "Epoch 146/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.9524 - accuracy: 0.6958\n",
            "Epoch 147/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9858 - accuracy: 0.7034\n",
            "Epoch 148/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.9532 - accuracy: 0.6911\n",
            "Epoch 149/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.9869 - accuracy: 0.6923\n",
            "Epoch 150/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9749 - accuracy: 0.6994\n",
            "Epoch 151/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.9751 - accuracy: 0.6823\n",
            "Epoch 152/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.9430 - accuracy: 0.6976\n",
            "Epoch 153/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9769 - accuracy: 0.6902\n",
            "Epoch 154/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 1.0176 - accuracy: 0.6734\n",
            "Epoch 155/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.9590 - accuracy: 0.6997\n",
            "Epoch 156/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.8811 - accuracy: 0.7172\n",
            "Epoch 157/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.9071 - accuracy: 0.7173\n",
            "Epoch 158/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.9652 - accuracy: 0.7002\n",
            "Epoch 159/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.8638 - accuracy: 0.7132\n",
            "Epoch 160/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9736 - accuracy: 0.6808\n",
            "Epoch 161/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.8988 - accuracy: 0.7190\n",
            "Epoch 162/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.9197 - accuracy: 0.7108\n",
            "Epoch 163/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.8916 - accuracy: 0.7081\n",
            "Epoch 164/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.8825 - accuracy: 0.7194\n",
            "Epoch 165/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.9392 - accuracy: 0.6954\n",
            "Epoch 166/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.9302 - accuracy: 0.7021\n",
            "Epoch 167/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9749 - accuracy: 0.7032\n",
            "Epoch 168/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.9101 - accuracy: 0.7104\n",
            "Epoch 169/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.8982 - accuracy: 0.7113\n",
            "Epoch 170/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.8696 - accuracy: 0.7276\n",
            "Epoch 171/200\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.9288 - accuracy: 0.7144\n",
            "Epoch 172/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.9876 - accuracy: 0.6804\n",
            "Epoch 173/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.9206 - accuracy: 0.7092\n",
            "Epoch 174/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.8714 - accuracy: 0.7327\n",
            "Epoch 175/200\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.9651 - accuracy: 0.7042\n",
            "Epoch 176/200\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.8943 - accuracy: 0.7012\n",
            "Epoch 177/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.9083 - accuracy: 0.7217\n",
            "Epoch 178/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.9053 - accuracy: 0.7134\n",
            "Epoch 179/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.8579 - accuracy: 0.7285\n",
            "Epoch 180/200\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.8826 - accuracy: 0.7189\n",
            "Epoch 181/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.9173 - accuracy: 0.7199\n",
            "Epoch 182/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.9845 - accuracy: 0.6917\n",
            "Epoch 183/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.8343 - accuracy: 0.7326\n",
            "Epoch 184/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.8802 - accuracy: 0.7102\n",
            "Epoch 185/200\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.8361 - accuracy: 0.7263\n",
            "Epoch 186/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.9105 - accuracy: 0.7088\n",
            "Epoch 187/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.8809 - accuracy: 0.7375\n",
            "Epoch 188/200\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.7930 - accuracy: 0.7560\n",
            "Epoch 189/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.8310 - accuracy: 0.7292\n",
            "Epoch 190/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.8268 - accuracy: 0.7303\n",
            "Epoch 191/200\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.8361 - accuracy: 0.7264\n",
            "Epoch 192/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.8270 - accuracy: 0.7371\n",
            "Epoch 193/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.9226 - accuracy: 0.7197\n",
            "Epoch 194/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.8917 - accuracy: 0.7194\n",
            "Epoch 195/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.9536 - accuracy: 0.7082\n",
            "Epoch 196/200\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.8107 - accuracy: 0.7367\n",
            "Epoch 197/200\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.8347 - accuracy: 0.7418\n",
            "Epoch 198/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.9079 - accuracy: 0.6989\n",
            "Epoch 199/200\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.8438 - accuracy: 0.7348\n",
            "Epoch 200/200\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.8008 - accuracy: 0.7493\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}